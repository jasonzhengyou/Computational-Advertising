## 机器学习规则--机器学习工程化的最佳实践		

Martin Zinkevich

这篇文档主要目的是来帮助那些具有一定机器学习基础想从谷歌的机器学习项目实践中获益的人。它呈现的是类似于“Google C++ Style Guide”风格的实践指南。 这篇文档适合上过机器学习的相关课程或者从事机器学习相关工作的人阅读。

#### 专业术语

Instance：

Label：

Feature：

Feature Column：

Example：

Model：

Metric：

Objective：

Pipeline：

### Overview

为了做出伟大的产品：

**做机器学习需要你像一个伟大的工程师，而不是像一个伟大的机器学习专家！**[do machine learning like the great engineer you are, not like the great machine learning expert you aren't]

实际上，在机器学习项目中你所面临的大多数问题是工程问题。即使一个拥有所有资源的伟大机器学习专家，项目中的绝大部分贡献来自于好的特征而不是机器学习算法。所以，最基础的方法需要：

1. 确保你管道是端到端的
2. 从一个合理的目标开始
3. 简单地添加一些易理解常识性的特征
4. 确保你的管道是稳定的

这种方法能够在很长的一段时间内让你项目保持收益和工作愉悦直到你没有简单的技巧来让项目走的更远。项目复杂性的增加会减缓产品未来版本的发行。

一旦你穷尽了小而简单技巧，使用高端的机器学习才是你未来的方向。

这篇文档包括四个部分：

1. 第一部分帮助你理解什么时候建立机器学习系统是正确的
2. 第二部分是关于你第一个管道的部署
3. 第三部分是关于有新特征添加到管道的启动和迭代问题，如何评估模型及线上线下的差异
4. 第四部分是关于项目到达瓶颈期时你该做什么
5. 最后，是一份相关工作的清单和一篇常用的示例的附录

### 在引入机器学习之前

**规则1: 不要害怕推出一个没有机器学习的产品**

机器学习虽然很酷，但是需要数据。理论上，你可以从利用其他数据来训练或者调整你在新产品中的模型，但是这样很可能会出现模型的表现不如简单基本的启发式规则。如果你认为机器学习能够给你一个100%的提升，同样的环境中一个启发式规则能带来50%的提升。

例如，你如果在app市场中想要对app进行排序，可以使用安装率或者安装数量来进行排序。如果想要在排序之前过滤掉垃圾app以及对应的发布者，不要害怕去使用人工识别的方法。如果你需要将联系人进行排序，可以使用联系频繁度规则进行排序（或者直接使用字母顺序排序）。总之，对于机器学习的需求如果在你项目或者产品中没有那么明显，就不要引入机器学习直到你有数据为止。

**规则2: 首先设计和实现指标**

在正式确定机器学习系统要做什么之前，利用当前系统搜集尽可能多的数据。这样做的理由如下：

1. 在早期更容易获得用户的许可
2. 如果你认为某些东西是未来要关注的，现在开始搜集相关数据形成历史数据集更有益未来的工作。
3. 如果你在设计系统的时候考虑到衡量的指标，未来的工作将会简单轻松多。尤其你不会希望自己在一堆日志文件中提取相关信息来进行处理以衡量你的指标。
4. 你会发现变和不变的信息。例如，假设你想要直接优化系统的日用户活跃量，在早期的操作过程中即使用户的体验发生戏剧性变化，日活跃度用户量也不怎么改变。

Google Plus 团队会衡量每次阅读，每次阅读的转发次数，每次阅读，每位用户的评论/阅读，每位用户的评论，每位用户的转发次数等展开次数，用于计算在投放时的帖子的质量。**同时注意在一个实验框架中如果你能够将用户分桶进行聚合统计很重要** [Also, note that an experiment framework, where you can group users into buckets and aggregate statistics by experiment, is important]。查看**规则12**。

对于收集指标应该抱着更自由的态度，这样你就会得到关于你系统更广的蓝图。注意到一个问题？添加一个指标并且追踪相关数据！对于某些指标上量的改变感到兴奋？添加一个指标并且追踪相关的数据。

**规则3: 启发式规则变得复杂后选择机器学习**

一个简单的启发式规则可以让你的产品实现基本的功能。一个复杂的启发式规则难以维护。一旦你有了数据和想要实现的简单想法就可以采用机器学习来实现了。在大多数的软件工程任务中，如果想要定时更新你方法，不管是基于启发式规则还是机器学习模型，你会发现机器学习模型都更容易更新和维护(参见规则16)。

### 机器学习第一阶段：你的第一个管道

专注于你第一个管道系统的基础架构。虽然想象着将要利用机器学习去实现你的宏伟蓝图很美好，但是如果你不能够对于你建立的管道有足够信心的话，你很难确定接下来会发生什么。

**规则4：让你的第一个模型简单并且保证你管道的基础架构的正确性**

第一个模型能够对你的产品会有一个很大的提升，所以它不需要那么的魔幻完美。但是在管道的中你会遇到比你想象的多的问题。在任何人想要使用你酷炫的新机器学习系统之前，你必须确定：

1. 如何使得你的学习算法得到训练样本
2. 能够区分出对于你系统来讲什么是好与坏的
3. 如何将你的模型融入到你的应用程序中。你可以将模型部署在线上实时使用模型，或者线下使用模型对样本进行处理并将结果存储在表格中。例如，你可能希望对网页进行一个预分类并将分类结果存储在表格中，同时你也可能希望使用模型在线对网页进行分类预测。

选择简单的特征能够更容易保证：

1. 模型能够得到正确的权重值
2. 模型能有一个合理的权重值
3. 模型能够在服务端能够准确get到对应的特征

一旦你的系统能够确保满足上述三条的要求，你已经完成了大部分工作。你的简单模型能够给你一个基准并且你可以使用这个基准去衡量其他模型。

**规则5: 将机器学习剥离，对你管道的基础架构进行单独测试**

确保管道的基础架构可以进行测试，并且将系统的训练模块也包含其中，这样你就可以围绕着训练模型进行各种测试。尤其：

1. 测试将数据导入到算法模型中。检查非稀疏的特征列经过管道后也应该是非稀疏的。在隐私权限允许的情况下，人工检查训练算法的输入数据情况。如果可能的话，将管道内特征数据进行统计检查同其他的地方进行比较，例如，RASTA
2. 将模型从训练算法中剥离出来进行测试。确保你的模型在训练环境和线上环境能得到相同的结果(参考规则37)。

机器学习具有不可预测性的特点，所以应该确保你已经对线上和线下用来生成样本的代码进行过测试，并且在线上可以加载或者使用一个固定的模型。同样，对于数据的理解和认识也非常重要。可以参考文档：



**规则7: 将启发式信息转变为特征或者将其单独进行处理**

通常尝试使用机器学习去解决的问题都不是完全是新的问题。例如排序问题，分类问题或者其他问题现在都有着成型的解决方案。这就意味着每类问题存在着一堆规则和启发式的信息。**这些相同的启发式信息能够在对机器学习模型或者方案调整的时候带来一定的惊喜**(These same heuristics can give you a lift when tweaked with machine learning)。有两个原因需要你关注你的启发式规则，无论它包含何种信息。第一，向融入了机器学习系统的转变过程变的平滑；第二，这些启发式规则包含了你不想丢弃的信息在里面。现在有四种方法来对已有的启发式规则进行处理：

1. 使用启发式信息进行预处理。




### 机器学习的第二个阶段：特征工程

在机器学习系统生命周期的第一个阶段，最重要的是把训练数据导入到学习系统中，得到感兴趣的测试指标和搭建服务架构。如果你已经完成了端到端的单元和系统测试，那么就可以开始第二阶段了：

第二阶段有许多比较容易实现的目标。例如将各种明显特征加入到系统中。因此，第二阶段的任务就是尽可能搜集到更多的特征并将他们按照某种意图进行组合生成特征向量。在这个阶段，原系统监测收集到各项指标数据都处于上升阶段。在这个阶段会开展很多的任务，这是个好时机将工程师聚集起来完成你所需要的所有数据的搜集工作。

**规则16: 有计划地建立模型和模型迭代**

不要期望你现在的模型是最后一个你建立的模型或者说一劳永逸了。因此，现在模型的复杂度直接影响到未来构建模型的速度。许多团队一个季度或者许多年才构建一个新模型。构建一个新模型有一下三个基本原因：

1. 你想出了新特征
2. 你对正则项进行了调整并且以新的方式融合新特征，或者
3. 你的业务目标或者目标函数进行了调整

不管怎么样，给模型一点关爱总是好的：**查看以训练样本呈现的数据可以帮助找到新的，旧的或者零碎的信号。** 所以，在建模型的过程中考虑添加、删除或者重现组合特征的难易程度。考虑一下复制新管道和验证它的正确性的难易程度。考虑一下是否能够让两个或者三个管道并发运行。Finally, don’t worry about whether feature 16 of 35 makes it into this version of the pipeline. You’ll get it next quarter.

**规则17: 从显而易见的特征开始而不是learned features**

这能够是个比较有争议的观点，但是它能够避免很多陷阱。首先，让我们描述learned feature：这是一种不是通过外部系统(例如，非监督聚类)或者模型自身的学习得到(例如，分解模型或者深度学习)的特征。虽然这些learned 特征都非常有用，但是它们同样会有很多的问题，所以它们不应该被加入到第一个模型中。

第一个问题是，分解模型和深度模型都是非凸的。因此，这就不能够保证经过迭代后能够找到全局最优值或者近似最优值，容易陷入局部最优值的陷阱中，迭代过程中寻找到的局部最优值也不同。这种迭代过程的变化中很难区分这种改变的影响对你的系统是有意义的还是只是一个随机的结果。通过创建一个没有深度的特征的模型，能够得到一个不错的可以作为基准衡量标准的performance。在该基准模型建立后，你就可以尝试更高大上的算法喽。

**规则18: 探索可以在不同场景中应用的内容特征**

通常机器学习系统只是你宏伟蓝图的一部分。例如，一个可能在What's Hot中使用的帖子，在它被展示在What‘s Hot之前已经有许多人在上面进行点赞，分享和评论了。如果你向Learner提供这些统计信息，他可以在一定场景下优化推广那些没有数据的新帖子。YouTube的 What Next功能中使用的观看者数目和共同观看者数目的数据就来自与YouTube Search，当然你也可以使用评论率来作为运算指标。最终，如果你拥有用户的反馈(action)数据并且将其作为标签(Label)，要明白可以将这些反馈信息在不同的场景下作为一个很好的特征。这些特征信息能够为你的应用场景提供新的内容。注意，这和个性化无关：首先弄清楚在应用场景中是否有人喜欢这个内容，然后弄清楚喜欢它的人群和喜欢的程度。

**规则19: 尽可能使用那些具体的功能(specific features)**

在海量数据场景下，训练百万个简单特征要比训练一个复杂的特征容易的多。`[Identifiers of documents being retrieved and canonicalized queries do not provide much generalization, but align your ranking with your labels on head queries.]`因此不要担心使用那些特征群组，群组中的每一个特征只能覆盖你数据中的一小部分，但是每个整个特征群组的覆盖率却到达90%。你可以使用正则化来消除那些只覆盖到很少部分数据的特征。

**规则20: 对已有的特征采用人们能够理解的方式[human-understandable ways]进行组合和修改来创建新的特征**

有很多种方法来组合和修改特征。像TensorFlow这样的机器学习系统提供了像“transformation”这样的功能来让你进行数据的预处理。其中两种标准的方法是离散化和特征交叉。

离散化就是将一个连续的特征转变为多个离散的特征。例如，一个特征为年龄，你可以构建一个特征值为1代表年龄小于18的离散特征，还可以构建另外一个特征值为1代表年龄为18-35的离散特征，以此类推。不要在这些区域划分的边界上过于纠结：基本的分位图就能有很好的效果[basic quantiles will give you most of the impact]。

对两个或者更多的特征列进行组合交叉。例如一个特征列(feature column)是一些代表相同性质的特征集合。例如：{男，女}，{上海，杭州，南京…}。特征交叉就是对一个特征列和其他特征列进行笛卡尔乘积运算组合成一个新特征。例如{男，女}X{上海，杭州，南京}进行交叉形成了新的特征{男，上海}。注意这只是对两个特征进行交叉操作，如果三个，四个，或者五个特征进行这种交叉操作的时候需要海量的数据来训练学习模型。

交叉操作产生的大量新的的特征列会使得模型过拟合。例如，在搜索排序场景中，在query中你有一个word的特征列，在document中也有一个word的特征列，如果你把这两个特征列进行交叉操作，这两个特征列的交叉操作产生大量的新特征。在对文本进行类似的操作的时候有两种方法。最严格的方法是进行点乘积(dot product)。这种方法最简单的形式是统计query和document之间相同的word数量，并将它作为一个离散特征。另外一种方法是相交(intersection)：如果query和document都有单词‘pony’会形成一个新特征进行表示；同样如果单词‘the’也这样也会形成一个新特征。

**规则21: 在线性模型中能够学习到的特征权值的数目和训练的数据量成比例**

有一些很好的统计学习理论是关于模型的复杂度的，但是特征数目和数据量成比例关系的这个基本规则你还是需要知道的。在和其他人谈话中我了解到，人们对于从1000个甚至100万个样本中能学习到什么呈怀疑的态度，主要是他们对于某些学习的方式感到困惑。关键点在于用来学习的数据样本规模：

1. 如果你涉及的是一个搜索排序问题，搜索词query和文档集document的单词数量是百万级的，只有1000个训练样本。这种情况下，你应该首先将document和query采用TF-IDF进行处理，然后将两者的TF-IDF的点乘积作为一个特征，再构建一打经过人工处理后的特征。1000左右的训练样本，一打特征。
2. 如果你的训练样本达到百万级，可以document和query的特征列进行一个映射操作，使用正则化或者其他方法来进行特征选择。这样你的特征规模达到百万级，但是正则化后特征数目将减少。千万级的训练样本，万级的特征
3. 如果你有10亿级甚至百亿级的样本，你可以将document的特征列和query的特征列进行交叉操作，再使用特征选择或者正则化进行处理。10亿级的训练样本，千万级的特征。

统计学习理论很少会给定一个准确的边界，但是可以给起始点的提供一些参考。最后，特征选择可以参考规则28.

**规则22:清除不再使用的特征**

未使用的特征可能会带来技术难题。如果你发现一个你不再使用的特征并且和其他特征形成的组合特征也不再有效，那么可以将该特征从你的系统中删除。保持你系统架构的清洁删除不必要的特征能够使你更快速地尝试其他的特征。如果可能的话保持能够随时添加特征的状态。

添加或者删除一个特征的时候应该考虑该特征的样本覆盖率。多少个样本拥有这个特征？例如，对于一些个性化的特征，假如只有8%的用户拥有这个特征，那么它可能并不那么有效。

同时，有些特征可能的重要程度可能超过它的覆盖率。例如，如果你有这样一个特征，只有1%的数据拥有该特征，但是这部分数据中的90%都是正样本，那么它就是一个非常值得添加到模型的特征。

#### 系统的人工分析

在进入机器学习的第三个阶段之前，怎样查看现有的模型并提出改进的策略非常重要。这些东西都不会在机器学习的相关课程中教授。与其说是一门科学还不如说是一门艺术，但是有几个反模式是可以避免的。

**规则23: 你并不是一个典型的终端用户**

`[This is perhaps the easiest way for a team to get bogged down. While there are a lot of benefits to fishfooding (using a prototype within your team) and dogfooding (using a prototype within your company), employees should look at whether the performance is correct.]` 一个形成差的改变策略将会被丢弃，任何看起来合理的策略都应该被进一步测试，无论是通过在其他平台上进行有尝的问卷调查还是对真实用户进行在线测试。

这样做有两个原因：其一，你离代码太近，很多时候容易带入个人偏好和情感因素；其二，你的时间太宝贵，可以计算一下几个工程师坐在一起开一个小时的会议只是为了讨论在其他平台上购买多少个标签的问题的成本问题。

如果你真的想要一些用户反馈，使用用户体验的方法。在早期阶段建立用户的画像然后再进行可用性测试。用户画像需要创建一个假想用户，例如，如果你的团队都是男性，可能有助于设计一个35岁的女性用户角色（完整的用户功能），看看它产生的结果，而不是10个结果25到40岁的男性。让实际的人在可用性测试中看到他们对您的网站（本地或远程）的反应也可以让您有一个全新的视角。

**规则24: 度量模型之间的差异**

在面向客户之前，检验新模型最简单并且有时候最有效的方法就是统计新模型和现有模型的差异。例如，如果你是一个排序问题，检验新模型的时候可以将新旧模型跑相同的查询实例，并查看结果的对称性差异大小(可以通过排序位置的权重)。如果差异很小，那么你不需要通过线上实验也可以宣称即使新模型上线改变也非常小。如果差异很大，并且确保其变化是朝好的方向。查看那些对称性差异比较大的查询可以帮助你定性地理解改变是什么样的。然而，要确保系统是可靠的。确保模型与自身比较具有比较低的(理想情况下为0)对称差异。

**规则25: 选择模型的时候，实际受益的性能表现比模型预测性能表现更重要**

你的模型是用来预估点击率的，然而关键的问题是你用点击率来做什么。如果你使用它来对文档排序，那么最终文档的排序结果比预测本身更重要。如果你用它来进行垃圾分类形成黑名单，那么预测准确性更重要。大多数的情况下，这两者的结果应该是一致的，即使不一致，两者之间的结果差异性也非常小。因此，如果系统做了一些改变，使得log 损失值变小了但是却降低了系统的表现，寻找其他的特征。当这种情况变得频繁后，是时候回到你的模型的目标进行重新评估了。

**规则26: 在已度量的错误中寻找模式，并且创建新特征**

对于那些模型判断错误的训练样本。在分类任务中，可能是正样本判断为负样本或者是负样本判定为正样本。在排序问题中，可能是一对正样本的排序位置低于负样本的排序位置。最重要的事情是机器学习系统知道这个样本是判定错误的如果能够给机会它可以进行修正。如果你给你的模型增加一个特征让它来修正错误，那么模型很有可能用它来进行结果的修正。

一旦你有一些被模型判断错误的样本，分析这些错误样本的特点趋势并排除已在现有特征集里面得到体现的。例如，通过对错误实例的分析，你得到了系统似乎有抑制长评论的趋势，那么可以添加评论长度作为模型特征。不需要对你添加的特征有太具体的认识。就像你添加评论长度作为特征，那么就需不要努力猜测长度在模型中的意义，仅仅需要添加一些特征让模型去得出它们的意义。这是最简单的到你想要的方法。

**规则27: 尝试对观察到的不好表现进行量化**

现有的损失函数不能够捕捉到系统中某些特性会让团队中的某些成员感到沮丧。这个时候他们需要通过任何方式将他们的抱怨通过数字来体现出来。例如，你可能认为在Play Search中太多的‘gag apps’得到展示，他们可以通过人工识别的方式来区分这些‘gag app’。如果你的问题是可以度量的，那么可以开始将他们作为特征，目标或者是指标。通用的规则是：度量是第一步，优化是第二步

**规则28: 注意短期的一致行为并不代表长期的行为一致**

假设您有一个新系统，它查看每个doc_id和exact_query，然后计算每个查询的每个文档的点击概率。你发现它的表现在side by sides和A/B testing都和你的系统一致，考虑到它的简单性，你将它上线。然而你注意到没有新的app被展示了。这是为什么？因为你的系统只是根据它自己的历史查询信息展示doc，不知道怎么对新的doc进行学习概率来展示。

了解这样的系统如何工作的唯一方法是让它只训练模型在线时获得的数据。这非常困难。

#### 线下和线上的偏差(Training-Serving Skew)

所谓的线下和线上的偏差指的是训练阶段的表现和线上服务的表现的差异。导致这种差异的原因：

- 在线下训练和线上服务管道处理数据存在差异
- 用于训练的数据和线上预测的数据发生了改变
- 模型和算法之间的反馈存在着循环



